# ğŸ§  Software Requirements Classification: Ambiguity Detection and FR/NFR Categorization

This repository contains the code and datasets used in a study focused on the classification of software requirements. The work is structured in two main tasks:

1. **Ambiguity Detection** â€“ Identifying whether a requirement statement is ambiguous.
2. **FR/NFR Classification** â€“ For non-ambiguous requirements, categorizing them as either **Functional Requirements (FR)** or **Non-Functional Requirements (NFR)**.

A range of deep learning models and embedding techniques have been evaluated to benchmark classification performance across multiple datasets.

---

## ğŸ“Š Datasets

The experiments were conducted on three publicly available datasets:

- **PROMISE**
- **Kaggle Fult Pron SRS**
- **FNFC** â€“ [Hosted on HuggingFace](https://huggingface.co/datasets/MSHD-IAU/FNFC-Functional_Non-Functional_Calssification/tree/main)

All datasets are included in the repository under relevant folders.

---

## ğŸ§ª Models & Embedding Methods

We tested **six neural architectures**, each combined with **four types of word embeddings**, resulting in 24 experimental setups:

### ğŸ§  Models:
- CNN
- Bi-CNN
- LSTM
- Bi-LSTM
- DNN
- GRU

### ğŸ”¤ Embeddings:
- GloVe (42B.300d)
- BERT (via Hugging Face Transformers)
- Word2Vec (Gensim)
- TF-IDF (Scikit-learn)

Each combination is organized in a directory named:  
`[model]-[embedding]`, e.g. `bilstm-glove`, `cnn-bert`, etc.

---

## ğŸ“ Project Structure

```
.
â”œâ”€â”€ BiLSTM
â”‚   â””â”€â”€ GloVe
    â””â”€â”€ BERT
    â””â”€â”€ TFIDF
    â””â”€â”€ Word2Vec
â”œâ”€â”€ LSTM
â”‚   â””â”€â”€ GloVe
    â””â”€â”€ BERT
    â””â”€â”€ TFIDF
    â””â”€â”€ Word2Vec
â”œâ”€â”€ BiCNN
â”‚   â””â”€â”€ GloVe
    â””â”€â”€ BERT
    â””â”€â”€ TFIDF
    â””â”€â”€ Word2Vec
â”œâ”€â”€ CNN
â”‚   â””â”€â”€ GloVe
    â””â”€â”€ BERT
    â””â”€â”€ TFIDF
    â””â”€â”€ Word2Vec
â”œâ”€â”€ DNN
â”‚   â””â”€â”€ GloVe
    â””â”€â”€ BERT
    â””â”€â”€ TFIDF
    â””â”€â”€ Word2Vec
â”œâ”€â”€ GRU
â”‚   â””â”€â”€ GloVe
    â””â”€â”€ BERT
    â””â”€â”€ TFIDF
    â””â”€â”€ Word2Vec
â””â”€â”€ Datasets
    â””â”€â”€PROMISE
    â””â”€â”€Kaggle
    â””â”€â”€FNFC
â”œâ”€â”€ README.md
â””â”€â”€ requirements.txt
```

---

## âš™ï¸ Setup & Installation

### 1. Clone the repository
```bash
git clone https://github.com/mahdikabootari/Software-Requirements-Classification.git
cd Software-Requirements-Classification
```

### 2. Create virtual environment and activate
```bash
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate
```

### 3. Install dependencies
```bash
pip install -r requirements.txt
```

---

## ğŸ“¥ Download GloVe Embeddings

Due to file size, the GloVe embeddings are not included in this repository.

â¡ï¸ Download `glove.42B.300d.txt` (1.9GB) from:  
ğŸ”— [https://nlp.stanford.edu/data/glove.42B.300d.zip](https://nlp.stanford.edu/data/glove.42B.300d.zip)

After downloading and extracting, place the file in:

```
embeddings/glove.42B.300d.txt
```

---

## ğŸš€ Running the Experiments

All experiments are provided as Jupyter Notebooks. For example:

```bash
jupyter notebook bilstm-glove/experiments.ipynb
```

Each notebook allows you to:

- Select a dataset
- Load embeddings
- Train and evaluate models
- View performance metrics (accuracy, F1, etc.)

---

## ğŸ’» Hardware Requirements

The models can be trained on both **CPU** and **GPU**.  
Using a GPU (e.g., via Google Colab or local CUDA) is recommended for faster training.

---

## ğŸ›  Dependencies

Main dependencies include:

- Python 3.8+
- Jupyter Notebook
- TensorFlow / Keras
- PyTorch
- Transformers
- Scikit-learn
- Gensim
- NumPy
- Pandas
- Seaborn
- Matplotlib

Install them using:

```bash
pip install -r requirements.txt
```

---

## ğŸ“§ Contact

Created by **Mahdi Kabootari**  
ğŸ“¬ kabootarimahdi2@gmail.com  
ğŸ”— [GitHub Profile](https://github.com/mahdikabootari)

---

## ğŸ“„ License
